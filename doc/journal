Avant juin 2016 :
	Réflexions et brouillons
	Premiers jets d'un outil générique permettant d'utiliser la technique
	de la génération évolutive, l'EvolutiveGenerator.
-------------------------------------------------------------------------------

6-22 juin 2016 :
	Réalisation d'une présentation pour passage devant M Réal et Mme Chevalier
	(cf tipe.odp)
	Recherche de documentation sur le sujet, trouvé :
		NeuroEvolution of Augmenting Topologies by MIT
-------------------------------------------------------------------------------

1-23 Juillet 2016 :
	...
	Objectif 1.0 :
		Adapter le jeu :
			- modification du jeu.
			- création d'un bridge permettant de faire le lien entre le
			logiciel de génération évolutive et le jeu.
-------------------------------------------------------------------------------

23 Juillet 2016 :
	Objectif 1.0 atteint

	Problème 1 :
		Le programme plante (très) souvent à l'extinction.

	Problème 2 :
		Pour pouvoir accélérer le jeu, il a fallut convertir les délais en
		nombres de frames, et ce en multipliant les temps par le framerate.
		Ne devrait-on pas calculer un nombre de frames absolu ?
		Il me semble que c'est ce qu'il faudrait faire, mais les résultats
		attendus semble déjà atteint avec la solution actuelle. Pourquoi ?
-------------------------------------------------------------------------------

11 Août 2016 :
	Il semblerait que le problème 1 soit dû à la librairie PulseAudio gérant
	le son.
	Objectif 1.1 :
		Enlever le son. Peut résoudre le problème 1.
	
	Objectif 1.2 :
		Fixer get_fps constant à 60 fps. Devrait résoudre le problème 2.
		
	Objectif 2 :
		Coder le processus de génération.
	
	Objectif 2.0 :
		Coder l'EvolutiveGenerator.
	
	Objectif 2.1 :
		Représenter l'IA.
	
	Objectif 2.2 :
		Coder les algorithmes de création, mutations et combinaisons.
-------------------------------------------------------------------------------

16 Août 2016 : Spécifications 2.1 et 2.2
	Réprésentation des données :
		IA :
			{ Neurones }
		Neurone :
			( Évènement, Action )
		Évènement :
			- nom
			- coordonnées (x, y)
		Action :
			- classe
			- durée
	Algorithmes :
		IA :
			create():
				On crée 3 à 6 neurones de manière équiprobable.
			mutate():
				20% de chance de créer un nouveau neurone
				10% de chance de détruire un neurone
				pour chaque neurone: 20% de chance de muter
			combine():
				On prend 50% des neurones de chaque parent (arrondi par excès).
		Neurone :
			create():
				On crée un évènement.
				On crée une action.
			mutate():
				On mute un de ces éléments:
					- l'évènement
					- l'action
		Évènement :
			create():
				On tire un évènement et une coor au pif.
			mutate():
				On change soit le nom soit les coordonnées de manière
				équiprobable.
				Changement des coordonnées :
					On tire un entier entre [-100;+100] qu'on ajoute à x.
					Idem avec y.
		Action :
			create():
				On tire une action et une durée dans [2;30].
			mutate():
				On change soit la classe soit la durée de manière équiprobable.
				Changement de la durée :
					On tire un entier entre [2;30] frames.
		
	Je décide finalement de séparer les modèles :
		- représentation en tant que données via 4 entités
		- manipulation en tant que GeneticElement via 4 factory
		- lecture des données et interaction avec l'event dispatcher dans la
		classe Neuron
-------------------------------------------------------------------------------

17 Août 2016 :
	Objectifs 2.0, 2.1 et 2.2 atteints
	Objectif 1.2 Fait
	
	Objectif 2.3 :
		Coder le Graduator, utilisant le bridge pour évaluer les IA.
		Lancer une première génération.
-------------------------------------------------------------------------------


18 Août 2016 :
	Objectif 2.3 atteint. Il reste quelques bugs à trouver/résoudre.
	Le problème 1 se révèle comme prévu très problématique. Sa résolution via
	l'objectif 1.1 devient une priorité.
	
	Objectif 2.4 : Tests
		Debug du programme d'évolution, écriture des tests unitaires.
	
	Objectif 2.5 : Writer
		Mettre en place une architecture permettant de sauvegarder les
		résultats des calculs et l'historique des évènements.
-------------------------------------------------------------------------------

22 Août 2016 :
	Objectif 1.1 atteint ! Bonne nouvelle : le problème 1 semble résolu. À
	confirmer cependant.
	
	Plan pour l'objectif 2.5 :
		- Écrire un composant Writer permettant de sauvegarder toutes les
		  données de la génération.
		- Mettre un event dispatcher comme pivot entre le Generator et le
		  Graduator avec émission d'évènements aux étapes clés de la
		  génération, permettant de greffer le Writer et d'autres middlewares
		  tels qu'un futur Logger, ouvrant la voie pour un Graduator,
		  asynchrone permettant d'évaluer plusieurs intelligences
		  simultanément ainsi que pour un pattern Strategy sur le choix d'un
		  Graduator.
		- Potentiel Reader pour lire les données et adaptation du Generator
		  pouvoir stopper et reprendre une génération.
	
	Spécification de l'architecture système des sauvegardes :
		results
			processus-00000
				generation-00 # Nb de zéros fc du nombre de générations prévues
					initial_pop
						- ia-000.json
						- ia-001.json
						...
					- generation
				generation-01
					selection
						- grading # lignes type : ia_id: score
						- final_grading.json
						- selection.json # ids
					population
						- ia-000.json
						- ia-001.json
						...
					- breeding # lignes type : 000 + 001 -> 000
					- generation.json # state
				...
				- processus.json # generations, pop_length, proportion, chance
-------------------------------------------------------------------------------

23 Août 2016 :
	Rapport à l'objectif 2.4 : le programme d'évolution semble fonctionner,
	les tests restent à faire (tests unitaires sur l'EvolutiveGenerator).
	
	Objectif 1.3 :
		Émettre tous les évènements et les prendre en compte dans la
		génération (pour l'instant seuls les blocs et les ennemis).
	
	Problème 3 : Temps de calcul
		Pour l'instant, le temps d'évaluation permis est calculé ainsi :
			time = min(1 + generation, 401)
		avec generation le numéro de l'itération.
		Cependant, un rapide calcul sur le nombre d'itération permet de se
		rendre compte qu'à 120 fps, l'évaluation d'une population de 2
		individus sur les 400 premières itérations prend 22 heures. Les
		populations utilisées représenteront bien plus que 2 individus.
		Des statistiques sur les premières générations que je vais faire vont
		permettre d'ajuster le calcul du temps. Il s'agit de trouver pour
		chaque itération un temps laissant les intelligences exprimer leur
		potentiel tout en étant le plus petit possible pour optimiser le temps
		de calcul. Une alternative pourrait également être ajuster
		dynamiquement le temps à chaque itération en fonction des résultats de
		l'itération précédante.
		Il apparaît toute fois assez improbable que l'optimisation du temps
		suffise à permettre d'effectuer la génération en un temps acceptable.
		La solution sera alors de former une communauté de personnes acceptant
		de me prêter de la puissance de calcul. L'idée serait de séparer le
		programme Python en un processeur (la partie programme d'évolution) et
		un client (la partie jeu) et de placer un serveur PHP entre les deux.
		Le processeur pourrait alors faire tourner la génération et envoyer
		les IA à évaluer au serveur, qui s'occuperait de redistribuer le
		travail entre les différents clients que l'on aurait préalablement
		distribués à la communauté. Un travail long et ambitieux mais qui
		s'avèrerait très intéressant (j'en suis déjà tout excité).
		Une autre alternative serait de mettre la main à la poche et de louer
		de la puissance de calcul (type Amazon Cloud) pour y faire tourner le
		programme. Un financement du lycée pourrait-il être envisagé ? Peut-
		être le coût serait-il suffisemment bas pour le financer moi-même ?
		Les deux cas me paraissent assez peu probables. L'avantage non
		négligeable de cette solution serait néanmoins un coût de
		développement supplémentaire quasi-nul.
	
	Objectif 2.6 :
		Faire tourner le jeu dans un thread/processus parallèle afin d'isoler
		chaque itération avec Pygame.
	
	Pour le moment je me concentre sur l'objectif 2.5.
	
	Premier longue génération terminée avec succès (gen=15, pop_length=20).
-------------------------------------------------------------------------------

24 Août 2016 :
	Clarification du vocabulaire utilisé (cf doc) :
		- processus (processus) :
			Désigne l'ensemble du traitement.
			Est composé :
			- d'une création d'une population initiale,
			- de multiples générations pour obtenir une population finale.
		- génération (generation) :
			Désigne à la fois une itération au sein d'un processus et la
			population qui en résulte.
			Est composée :
			- d'une sélection,
			- d'une étape de reproduction.
		- sélection (selection) :
			Évalue (grade) l'ensemble de la population puis en sélectionne
			(select) un sous-ensemble.
		- étape de reproduction (breeding) :
			Reproduction des individus de la sélection pour former une nouvelle
			population.
-------------------------------------------------------------------------------

25 Août 2016 :
	Objectif 2.5 atteint ! (Ouf ! C'était un gros morceau !) Et ça fonctionne !
	Report du Reader (dernier point de l'objectif 2.5) à l'objectif 2.7.
	
	Objectif 2.7 : dans la continuation du 2.5
		- Écrire deux Logger, un ConsoleLogger et un SystemLogger pour être
		  capable de suivre un processus et d'en garder une trace (plus
		  efficace que le Writer en ce qui concerne le suivi du programme).
		- Écrire un Reader et adapter le Generator pour être capable de
		  reprendre un processus coupé à n'importe quel moment.
		  Ajouter un système de pause propre.
-------------------------------------------------------------------------------

26 Août 2016 :
	Écriture des Logger terminée. Je m'attaque au Reader.
-------------------------------------------------------------------------------

28 Août 2016 :
	Le Reader est écrit mais il s'avère que j'ai largement sous-estimé
	l'effort nécessaire à l'adaptation du Generator. J'ai pour le moment
	construit un GeneratorManager chargé de lancer et stopper puis
	théoriquement pouvoir faire reprendre un processus. Mais deux problèmes se
	posent à présent:
	- Comment organiser le Generator de sorte à pouvoir reprendre un processus
	  arrêté en cours de génération ? C'est un problème délicat qui va encore
	  nécessiter réflexion.
	- Comment pouvoir réellement contrôler le Generator en cours de processus ?
	  Il paraît évident qu'il faille pour cela l'isoler dans un thread afin
	  qu'il puisse s'executer parallèlement à un script écoutant des entrées
	  utilisateur. Il va encore une fois adapter le Generator et organiser
	  l'échange avec celui-ci, peut-être en créant un miroir de son dispatcher.
	Bref, beaucoup de boulot délicat en vue.
-------------------------------------------------------------------------------

28 Août 2016 :
	J'ai trouvé LA solution pour adapter le Generator. L'idée est réorganiser
	le workflow pour passer d'une programmation fonctionnelle à une
	programmation plus "orientée évènement".
	Plan pour l'adaptation du Generator:
		- Réorganisation des méthodes:
			- init() se charge désormais de l'initialisation du processus
			actuellement faite dans process().
			- select() se charge désormais de la sélection uniquement après
			l'évaluation des individus. On a donc deux étapes distinctes
			grading et selection (maj du voc).
		- Réorganisation du workflow:
			- Supression de la boucle principale. Les méthodes process() et
			 generate() disparaissent donc. À la place, chaque méthode émet un
			 évènement indiquant qu'elle a fini et permettant à la suivante
			 d'écouter cet event. Le processus s'exécute donc entièrement par
			 propagation d'évènements de méthode à méthode.
			- Les données internes du processus sont centralisée dans un objet
			  ProcessusState qui est passé par chaque event.
		- L'avantage de cette méthode:
			TL;DR Permet d'arrêter et de relancer le processus à n'importe
			      quelle étape.
			- Propre, évite de passer toutes les infos du state de méthode en
			méthode et d'enfermer toutes les instructions de chaque méthode
			dans des structures conditionnelles.
			- La méthode process() (à renommer du coup ?) n'a plus qu'à lancer
			l'évènement initial ou n'importe quel autre évènement du processus
			simplement en analysant le ProcessusState.
			- Permet d'office une future évaluation asynchrone.
			- Centraliser les données dans le ProcessusState amène une
			convention d'écriture entre les différents composants externes au
			Generator (Writer, Logger, Reader) et donc une plus grande
			interopérabilité. Permet notamment d'alléger le Reader en écrivant
			directement le state.
	C'est parti !
	
	Objectif 2.8: Évaluation asynchrone
		Dans la continuation du 2.6, évaluer chaque IA de manière asynchrone.
-------------------------------------------------------------------------------

Septembre - 20 Octobre 2016 :
	Pause dans le développement, réflexion sur les autres attentes du TIPE.
	Ma prof de maths suit désormais l'avancement de mon TIPE.
-------------------------------------------------------------------------------

22 Octobre 2016 :
	Rendez-vous avec Arthur Caron, ingénieur en informatique et amateur de
	conception d'intelligences artificielles. Il m'a donné plusieurs pistes de
	recherche pour la réalisation d'un état de l'art, notamment de me
	renseigner sur AlphaGo, de lire "L'intelligence artificielle pour les
	développeurs" et doit m'envoyer une autre référence intéressante par mail.
	Son conseil : utiliser l'exemple récent des millions de dollars investis
	par Google dans AlphaGo pour montrer l'intérêt du sujet.
-------------------------------------------------------------------------------

25 Octobre 2016 :
	Reprise du développement, Objectif 2.7
-------------------------------------------------------------------------------

27 Octobre 2016 :
	Je peux annoncer avec plaisir que... la restructuration du Generator en
	obtant pour un workflow basé sur l'enchainement d'évènements, tel que
	décrit le 28 Août, est achevée !
	Je peux donc à présent d'avancer sur le 2.7. L'objectif est à terme de
	pouvoir effectuer trois actions :
	
	Objectif 3.0 : Interface simple en console
		Construire 3 commandes permettant de :
		- Lancer un nouveau processus
		- Reprendre un processus stoppé
		- Regarder l'individu le plus performant d'un processus en action.
	
		+ Ajouter une méthode pour stopper l'éxécution d'un processus ? Ou
		simplement faire CRL+C.
-------------------------------------------------------------------------------

29 Octobre 2016 :
	Et... Objectif 2.7 atteint ! Et en prime, le système de commandes est fait,
	avec 2 commandes fonctionnelles : new & resume. La troisième commande play
	reste à coder.
	Précision : à défaut d'un "vrai" système de pause, le système de pause
	mis en place est : lever un KeyboardInterrupt (CRL+C), les cas critiques
	étant pris en charge (ie. pendant l'écriture d'un generation.json).
-------------------------------------------------------------------------------

30 Octobre 2016 :
	Objectif 3.0 atteint.
	
	Objectif 3.1 :
		Ajouter une variante de la commande new: faire tourner le Generator
		jusqu'à obtenir une ia qui finit le niveau. Implémentation : rendre
		paramètre generations optionnel ou lui attribuer une valeur spéciale.
	
	#LObjectifLePlusRapideDuMondeParceQuOnAvaitJusteOubliéDeLeCoderAvantLol
-------------------------------------------------------------------------------

1 Novembre 2016 :
	Ajout de la reprise d'évaluation en cours (on grading.progress).
	Objectif 3.1 atteint.
	Objectif 1.3 rempli. Seuls les 4 principaux GameEvents sont émis.
	J'ai établi les probabilités suivantes pour le tirage aléatoire de
	l'évènement d'un neurone :
		- 90% de chance de tirer un bloc
		- 10% de chance de tirer parmi (ennemi, bonus, pièce)
	De sorte que la détection des blocs, qui est le composant fondamental du
	comportement des IA, soit largement prédominant. La détection d'autres
	évènements viendra perfectionner le comportement.
-------------------------------------------------------------------------------

14 Novembre 2016 :
	Debug de la commande play.

	MESDAMES ET MESSIEURS, J'AI L'HONNEUR DE VOUS ANNONCER QUE LA PREMIERE
	VERSION DE MON GÉNÉRATEUR D'INTELLIGENCE ARTIFICIELLE POUR MARIO BROS
	EST PRETE !
	Sortie de la v1.0.
-------------------------------------------------------------------------------

15 Novembre 2016 :
	Quelques optimisations de performances.
	
	Test de performances :
		Commande : new 10 --generations=5
		Résultats :
			commit 20e8f45931fa1c686d908410248e47cb8040e87b (v1.0) 03:40:26 min
			commit 165f5a3f6f2d7a8f02481da2b2fec6c14865f3b2 (auj.) 00:22:46 min
		Conclusion :
			Amélioration sur le début de génération d'un facteur 9.5
-------------------------------------------------------------------------------

20 Novembre 2016 :
	Nouveau but : Optimiser au maximum le temps nécessaire à l'évaluation.
	Hypothèse : temps d'évaluation = O(temps nécessaire à l'affichage)
	
	Objectif 1.4 : Optimisation - Réimplémentation de Pygame
		Réimplémenter Pygame pour ne pas avoir à afficher le jeu.
-------------------------------------------------------------------------------

26-27 Novembre 2016 :
	J'ai fait tourner une première génération pendant la semaine.
	Je dois préparer pour lundi une présentation de mon avancement pour ma prof
	de maths.
	J'ai trois nouveaux petits objectifs :
	
	Objectif 1.5 : Optimisation - Réduction des temps d'évaluation
		Écrire un composant GameOptimizer pour réduire les temps de calcul en
		détectant les IA qui font du surplace et des boucles spatiales.
	
	Objectif 3.2 : Graphiques
		Écrire une commande permettant de tracer des graphiques des résultats,
		ou fabriquant un fichier excel avec tous les résultats.
	
	Objectif 3.3 : Amélioration de play
		Améliorer la commande play pour pouvoir visualiser n'importe quelle IA.
		Les paramètres présentent désormais la syntaxe suivante :
			play {processus_id} Afficher la meilleure IA de tout le processus
								(actuellement de la dernière génération)
			play {processus_id} {generation_id} De la génération
			play {processus_id} {generation_id} {ia_id} Affiche l'IA.
	
	Objectif 3.3 atteint.
	Objectif 3.2 atteint: nouvelle commande print
	J'ai divisé par 2 le temps maximal alloué à chaque IA.
	Objectif 1.5 atteint avec la détection des boucles !
	
	Algorithme de détection des boucles :
		Soit l'application Approx qui va de l'espace des points P dans un
		espace restreint P' inclu dans P, surjective, dont chaque image a pour
		antécédent un carré de 10x10 points du plan discret P.
		On peut alors découper P en un ensemble de carrés ayant pour image par
		Approx un singleton.
		On fait donc l'approximation suivante :
			Soit x, y deux points par lesquels l'IA passe,
			x == y ssi Approx(x) == Approx(y)
			c'est à dire qu'ils sont relativement proches.
		On retient les images par Approx des 720 derniers points par lesquels
		est passé l'IA.
		Au bout de 15 sec de jeu, si l'IA passe par 5 points ayant la meme
		approximation durant les 720 dernières frames, on considère qu'elle
		fait des boucles.
	
	Ajout de l'option --show permettant de voir les intelligences durant leur
	évaluation a été ajouté aux commandes new et resume.
	
	J'ai généré un graphique des résultats obtenus pendant la semaine.
	Deux problèmes se soulèvent :
	
	Problème 4 :
		L'application plante au bout de 6 heures, à cause des appels récursifs
		remplissant la mémoire, du à la mise en place de l'Objectif 2.7.
		Une légère réadaptation du Generator est nécessaire.
	
	Problème 5 :
		Les scores stagnent à partir d'un certain temps car les innovations
		phénotypiques importantes ne semblent pas etre préservées au cours
		des multiples générations, relevant sans doute d'une complexité
		génotypique trop importante. Une analyse plus approfondie des résultats
		est nécessaire, et la solution consistera surement en une modification
		de l'algorithme génétique.
	
	Problème 6 :
		Les conditions de replay des IA n'étant pas exactement les memes que
		celles d'évaluation, certains visionnages ne sont pas fidèles aux
		performances des IA en évaluation.
	
	Ajout des option --chance et --proportion à la commande new.
	Ajout d'une option --as-grading à la commande play.
	Le problème 6 est réglé au mieux, mais restera un problème.
	
	Objectif 2.9 : Réadaptation du Generator (Pb 4)
	
	Objectif 2.10 : Évolution de l'algorithme (Pb 5)
		Pour tenter d'apporter une solution au problème 5, je propose d'ajouter
		un paramètre de survie. Il s'agit de modifier l'étape de formation de
		la nouvelle génération :
		la nouvelle génération sera constituée des 10% meilleurs individus de
		la sélection de la génération parente, puis complétée par reproduction.
		
		L'avantage de cette solution est de préserver les innovations
		évolutives les plus importantes qui influeront ainsi sur toutes les
		reproductions ultérieures, jusqu'à ce que des innovations plus
		avantageuses les remplacent. De plus, l'impact sur les innovations
		mineures est moindre puisqu'on ne leur enlève qu'environ 28% de
		l'espace génotypique (survie de 10% de la sélection + 20%*90%). Ce qui
		à la réflexion semble faire beaucoup en fait. Mais heuresement parmi
		ces 28%, seuls 10% survivent tels quels tandis que les 18% autres se
		retrouvent après reproduction, donc mutation (donc potentielle
		évolution). Les 10% qui survivent tels quels représentent donc une
		"banque de sauvegarde" des meilleures évolutions, à l'abri de la
		dillution en attendant que de meilleures viennent les surclassées.
-------------------------------------------------------------------------------

21 Mai 2017 :

	Objectif 2.9 atteint.

	Idées d'amélioration suite à la lecture des bouquins :
	v	- Repasser à une version iterative du Generator
		- Remplacer le mot niveau par "terrain".
		- Remplacer les termes "Génération évolutive" par "Algorithme génétique".
		
		- Chaîner tous les allèles et remplacer la reproduction par deux
		crossing-over. (Mise en pratique de la théorie des building blocks)
		- Pour rendre la fonction d’évaluation la plus continue possible,
		ajouter un critère sur la hauteur maximale sautée. On peut aussi
		ajouter des critères sur la hauteur maximale sautée sur les n derniers
		sauts, ainsi que la vitesse moyenne.
		- Modifier les probas pour ajouter des sauts plus hauts avec une plus
		forte probabilité.
		- Modifier la méthode de sélection pour la roulette biaisée, plus
		précise que la méthode de sélection des n meilleures, + caractère
		élitiste déjà mis en place.
		- Lors des mutations, utiliser une distribution normale autour de la
		valeur actuelle.
-------------------------------------------------------------------------------

22 Mai 2017 :
	Objectif 2.10.0 : Chaîner les allèles et remplacer la reproduction par demi crossing-over.
	
	Objectif 2.10.0 atteint.
	Fixe la limite minimale des neurons d'une IA à 3.
